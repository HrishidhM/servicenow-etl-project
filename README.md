# ServiceNow Incident ETL Pipeline  
**Technologies:** PostgreSQL, DBT, Apache Airflow, Apache Superset, Docker  

This project demonstrates an end-to-end ETL pipeline for **ServiceNow Incident Ticket Analysis**.  
It includes ingestion, transformation, orchestration, automated testing, and interactive dashboarding.

---

## ğŸ”„ Architecture Flow

CSV File (tickets.csv)
|
â–¼
PostgreSQL (Raw Schema)
|
â–¼
+------------------+
| DBT Models |
+------------------+
|
â–¼
Staging â†’ Fact â†’ Summary Models
|
â–¼
Apache Airflow
(Daily Automated Pipeline)
|
â–¼
Apache Superset Dashboard


---

## ğŸš€ Pipeline Overview

### **1ï¸âƒ£ Data Ingestion (Airflow â†’ PostgreSQL)**  
Airflow reads the `tickets.csv` and loads it into PostgreSQL under:

- Schema: `servicenow_raw`
- Table: `incidents_raw`

---

### **2ï¸âƒ£ Data Transformation (DBT)**  
DBT models create:

#### **Staging Layer**
- Cleans raw data  
- Removes duplicates  
- Standardizes formats  
- Converts timestamps  
- Extracts Year, Month, Day  

#### **Fact Layer**
- Computes:  
  - Resolution time  
  - SLA breach flags  
  - Assignment histories  

#### **Summary Layer**
- Monthly ticket metrics  
- Average resolution time  
- Ticket closure rate  
- Category/Priority insights  

DBT tests included:  
âœ” Not null  
âœ” Unique key  
âœ” Relationship checks  

---

### **3ï¸âƒ£ Orchestration (Apache Airflow)**  
A single DAG performs:

1. Ingest CSV â†’ PostgreSQL  
2. Run DBT models  
3. Run DBT tests  
4. Send status  

Schedule: **Daily (`@daily`)**

---

### **4ï¸âƒ£ Dashboarding (Apache Superset)**  
Includes visualizations for:

- Monthly ticket trends  
- Resolution time analysis  
- Priority/category breakdowns  
- Assignment group performance  
- Ticket closure rate  

Dashboard is exported at:


---

## ğŸ› ï¸ How to Run Locally

### **Prerequisites**
- Docker installed  
- Python 3.10+  
- DBT installed (`pip install dbt-postgres`)  

---

### **Step 1: Start Airflow**


Airflow UI:  
ğŸ‘‰ http://localhost:8080/

---

### **Step 2: Run DBT Transformations**

Navigate to DBT folder:


---

## ğŸš« Sensitive Files Not Included
For security reasons, the following are **not committed**:

- `profiles.yml`
- Raw full CSV data  
- Airflow logs  
- DBT target folders  

---

## âœ¨ Deliverables Checklist

- âœ” Airflow DAG  
- âœ” DBT Project (Staging â†’ Fact â†’ Summary Models)  
- âœ” DBT Tests  
- âœ” PostgreSQL schema design  
- âœ” Superset Dashboard Export  
- âœ” Full project hosted on GitHub  
- âœ” README with documentation  

---

 

---

